{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad056b3",
   "metadata": {},
   "source": [
    "## S&P 500 Stocks Return Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95209223",
   "metadata": {},
   "source": [
    "### Features Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108da7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a5ad6f",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "df = pd.read_csv('datashare.csv')"
=======
    "df = pd.read_csv('fc_data.csv')"
>>>>>>> a012886 (final update)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a74a80f",
   "metadata": {},
   "source": [
    "%%% This Version: April 2019. @copyright Shihao Gu, Bryan Kelly and Dacheng Xiu\n",
    "%%% If you use the dataset, please cite the paper \"Empirical Asset Pricing via Machine Learning\" (2018) and \"Autoencoder Asset Pricing Models.\" (2019)\n",
    "\n",
    "Firm Characteristics Dataset Description:\n",
    "\n",
    "1.DATE: The end day of each month (YYYYMMDD) \n",
    "2.permno: CRSP Permanent Company Number\n",
    "3-96. 94 Lagged Firm Characteristics (Details are in the appendix of our paper)\n",
    "97.sic2: The first two digits of the Standard Industrial Classification code on DATE\n",
    "\n",
    "Most of these characteristics are released to the public with a delay. To avoid the forward-looking bias, we assume that monthly characteristics are delayed by at most 1 month, quarterly with at least 4 months lag, and annual with at least 6 months lag. Therefore, in order to predict returns at month t + 1, we use most recent monthly characteristics at the end of month t, most recent quarterly data by end t − 4, and most recent annual data by end t − 6. In this dataset, we've already adjusted the lags. (e.g. When DATE=19570329 in our dataset, you can use the monthly RET at 195703 as the response variable.) \n",
    "\n",
    "Note: CRSP returns are not included. They are accessible from WRDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee8642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9c2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d524e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aeb792",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Standardize the column names\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start date and end date of the sample\n",
<<<<<<< HEAD
    "stdt = pd.to_datetime('20030101', format='%Y%m%d')\n",
    "nddt = pd.to_datetime('20201231', format='%Y%m%d')\n",
    "\n",
    "df['date'] = pd.to_datetime(df_['date'],format='%Y-%m-%d')+pd.offsets.MonthEnd(0)\n",
    "df = df[(df['date']>=stdt)&(df['date']<=nddt)].reset_index(drop=True)\n",
=======
    "# stdt = pd.to_datetime('19700101', format='%Y%m%d')\n",
    "# nddt = pd.to_datetime('20211231', format='%Y%m%d')\n",
    "\n",
    "df['date'] = pd.to_datetime(df_['date'],format='%Y-%m-%d')+pd.offsets.MonthEnd(0)\n",
    "# df = df[(df['date']>=stdt)&(df['date']<=nddt)].reset_index(drop=True)\n",
>>>>>>> a012886 (final update)
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce67713",
   "metadata": {},
   "source": [
    "### Merge SP500 return data from CRSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66002c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install wrds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d073200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrds\n",
    "conn=wrds.Connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46b62d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = conn.raw_sql(\"\"\"\n",
    "                        select a.*, b.date\n",
    "                        from crsp.msp500list as a,\n",
    "                        crsp.msf as b\n",
    "                        where a.permno=b.permno\n",
    "                        and b.date >= a.start and b.date<= a.ending\n",
    "                        and b.date>='01/01/2003'\n",
    "                        order by date;\n",
    "                        \"\"\", date_cols=['start', 'ending', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50669e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500['date'] = pd.to_datetime(sp500['date'],format='%Y-%m-%d')+pd.offsets.MonthEnd(0)\n",
    "sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4171d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames\n",
    "df = df.merge(sp500, on=['permno', 'date'])\n",
    "df = df.drop(columns=['start', 'ending'])\n",
    "df = df.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_weighted_ret(mv, ret):\n",
    "    return (ret * mv).groupby(mv.index).sum() / mv.groupby(mv.index).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f46869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the value-weighted return\n",
    "sp500_ret = value_weighted_ret(df['mvel1'], df['ret_x'])\n",
    "sp500_ret.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec9b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffca0902",
   "metadata": {},
   "outputs": [],
   "source": [
    "char = list(set(df.columns).difference({'permno','date','sharout','mve0','sic2','prc','zerotrade', 'ret'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089e8f96",
   "metadata": {},
   "source": [
    "### Add macroeconomic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb59c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ma = pd.read_csv(\"macro.csv\")\n",
    "data_ma.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496029e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ma_predictors = ['dp_sp','ep_sp','bm_sp','ntis','tbl','tms','dfy','svar']\n",
    "data_ma['Index'] = data_ma['Index'].str.replace(',','').astype('float64')\n",
    "data_ma['dp_sp'] = data_ma['D12']/data_ma['Index']\n",
    "data_ma['ep_sp'] = data_ma['E12']/data_ma['Index']\n",
    "data_ma.rename({'b/m':'bm_sp'},axis=1,inplace=True)\n",
    "data_ma['tms'] = data_ma['lty']-data_ma['tbl']\n",
    "data_ma['dfy'] = data_ma['BAA']-data_ma['AAA']\n",
    "data_ma = data_ma[['yyyymm']+ma_predictors+['Rfree']]\n",
    "data_ma['yyyymm'] = pd.to_datetime(data_ma['yyyymm'],format='%Y%m')+pd.offsets.MonthEnd(0)\n",
    "data_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db9b9df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_ma = data_ma.set_index('yyyymm').loc[sp500_ret.index]\n",
    "data_ma['ret'] = sp500_ret - data_ma['Rfree'] # equity risk premium\n",
    "data_ma = data_ma.drop(columns='Rfree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecccc77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fill na with cross-sectional median\n",
    "for ch in char:\n",
    "     df[ch] = df.groupby('date')[ch].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67748eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ma_long = pd.merge(df['date'],data_ma,left_on='date',right_on='yyyymm',how='left')\n",
    "for fc in char:\n",
    "    for mp in ma_predictors:\n",
    "        df[fc+'*'+mp] = df[fc]*data_ma_long[mp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bc1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c9ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69966939",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_char = list(set(df.columns).difference({'permno','date','sharout','mve0','sic2','prc','zerotrade', 'ret'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde5dc9",
   "metadata": {},
   "source": [
    "## EDA ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5896104",
   "metadata": {},
   "source": [
    "### Time-series Analysis of Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79e2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3893ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(sp500_ret, linestyle='-', color='b')\n",
    "plt.title('S&P500 Return Time Series')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Return')\n",
    "plt.grid(True)\n",
    "plt.savefig('figures/sp500_return.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ff805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plot_acf(sp500_ret, alpha=0.01)  # Adjust the number of lags as needed\n",
    "\n",
    "plt.title('ACF Plot of Returns')\n",
    "plt.xlabel('Lags')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.savefig('figures/acf.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1921dc57",
   "metadata": {},
   "source": [
    "Hint: Use lag(5) return as additional feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return distribution\n",
    "plt.figure(figsize=(5,3))\n",
    "\n",
    "df['ret'].plot.hist(bins=50)\n",
    "plt.xlabel('ret')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b040388",
   "metadata": {},
   "source": [
    "### Feature Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047dc81d",
   "metadata": {},
   "source": [
    "pairwise correlation and corr. with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77a2d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6463e967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,18))\n",
    "sns.heatmap(data=df[characteristics].corr(), cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top correlated features\n",
    "c = df[char].corr().abs()\n",
    "s = c.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\").reset_index()\n",
    "so.columns = ['col_1','col_2', 'corr']\n",
    "so = so.sort_values(by = ['corr', 'col_1'], ascending = False)\n",
    "so = so[so['corr']!=1]\n",
    "so = so.iloc[::2].reset_index(drop=True)\n",
    "# so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c40cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr = np.unique(so.iloc[:12,:2].unstack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556dc9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr = np.random.permutation(high_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa4bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6,4))\n",
    "sns.heatmap(data=df[high_corr].corr(), cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/corr_heatmap.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43efbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a threshold for correlation\n",
    "thres = 0.7\n",
    "\n",
    "# Find and drop highly correlated features\n",
    "high_corr1 = set()\n",
    "for i in range(len(c.columns)):\n",
    "    for j in range(i):\n",
    "        if c.iloc[i, j] > thres:\n",
    "            col = c.columns[i]\n",
    "            high_corr1.add(col)\n",
    "print(high_corr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d13876",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee3b7e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# high_corr1 = list({'betasq', 'grltnoa', 'acc', 'retvol', 'lgr', 'mve_ia', 'currat', 'baspread', 'pchquick', 'stdacc', 'orgcap'})\n",
    "df = df.drop(columns=high_corr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa6efde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding columns that contain any of the substrings\n",
    "col_to_drop = [col for col in df.columns if any(substring in col for substring in high_corr1)]\n",
    "\n",
    "# Dropping the identified columns\n",
    "df = df.drop(columns=col_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d76cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adabbc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_char = list(set(new_char).difference(col_to_drop).difference(high_corr1))\n",
    "len(new_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11255020",
   "metadata": {},
   "source": [
    "### Relationship with Target: scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45edd838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'ret_x': 'ret'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter('bm','ret',figsize=(5,3),alpha=0.1,s=10)\n",
    "plt.title(\"Scatter Plot of bm and ret\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/bm_ret.png',dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7da092",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in new_char:\n",
    "    df.plot.scatter(feature, 'ret', alpha=0.1, s=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0440fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['zerotrade']>0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fefcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrete variable\n",
    "df['nincr'].value_counts() #Number of earnings increases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3969ceca",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c25017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34660faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_split(df, n_chunks=8, train_chunks=2, val_chunks=1, test_chunks=1):\n",
    "    if train_chunks + val_chunks + test_chunks > n_chunks:\n",
    "        raise ValueError(\"The sum of train, validation, and test chunks cannot exceed the total number of chunks\")\n",
    "    \n",
    "    # Calculate the number of rows per chunk\n",
    "    chunk_size = len(df.index.unique()) // n_chunks\n",
    "    \n",
    "    # Define the start index of the first train set\n",
    "    train_start_idx = 0\n",
    "\n",
    "    for i in range(0,5):\n",
    "        \n",
    "        # Calculate indices for train, validation, and test sets\n",
    "        train_end_idx = train_start_idx + train_chunks * chunk_size\n",
    "        val_end_idx = train_end_idx + val_chunks * chunk_size\n",
    "        test_end_idx = val_end_idx + test_chunks * chunk_size\n",
    "        train_chunks+=1\n",
    "        \n",
    "        # Yield the indices for the current split\n",
    "        yield (df.iloc[train_start_idx:train_end_idx].index, \n",
    "               df.iloc[train_end_idx:val_end_idx].index, \n",
    "               df.iloc[val_end_idx:test_end_idx].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541d299f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594766e4",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a0134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['sic2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03ba5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_na = (df[char].isnull().sum() / len(df[char])).reset_index()\n",
    "num_na.columns = ['field','proportion']\n",
    "num_na = num_na.sort_values(by = 'proportion', ascending = True)\n",
    "ind = np.arange(num_na.shape[0])\n",
    "fig, ax = plt.subplots(figsize=(18,12))\n",
    "rects = ax.bar(ind, num_na.proportion.values, color='blue')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(num_na.field.values, rotation='vertical')\n",
    "ax.set_ylabel(\"proportion of missing values\")\n",
    "ax.set_title(\"Proportion of missing values in each column\", fontsize=16)\n",
    "ax.yaxis.set_tick_params(labelsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07aa5b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list(num_na[num_na.iloc[:,1]>0.4]['field'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2b20a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_char = list(set(new_char).difference(num_na[num_na.iloc[:,1]>0.4]['field']))\n",
    "len(new_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9456530f",
   "metadata": {},
   "source": [
    "There are 71 rows containing missing values from the 83 firm characteristics, including sic2 which is industry information (categorical variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ee1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class Rank(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.groupby(X.index).rank(axis=0, method='average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab125e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_ftrs = new_char\n",
    "cat_ftrs = ['sic2']\n",
    "\n",
    "# categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'))])\n",
    "\n",
    "# continuous features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('rank', Rank()),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf7c80",
   "metadata": {},
   "source": [
    "## ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa9d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af6e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = df.groupby(df.index).apply(lambda x: x.iloc[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290341cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_pipeline(X, y, preprocessor, ml_algo, param_grid):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter tuning for time series data.\n",
    "\n",
    "    :param X: Unprocessed feature matrix.\n",
    "    :param y: Target variable.\n",
    "    :param preprocessor: A ColumnTransformer for preprocessing.\n",
    "    :param ml_algo: An initialized machine learning algorithm.\n",
    "    :param param_grid: A dictionary containing hyperparameters and their respective ranges.\n",
    "    :return: Dictionary containing the best hyperparameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    test_scores = []\n",
    "    best_models = []\n",
    "\n",
    "    # Perform custom time series split\n",
    "    for train_idx, val_idx, test_idx in recursive_split(df_date):\n",
    "#         print(train_idx, val_idx, test_idx)\n",
    "        # Split the data\n",
    "        X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n",
    "        X_val, y_val = X.loc[val_idx], y.loc[val_idx]\n",
    "        X_test, y_test = X.loc[test_idx], y.loc[test_idx]\n",
    "\n",
    "        X_train = preprocessor.fit_transform(X_train)\n",
    "        X_val = preprocessor.transform(X_val)\n",
    "        X_test = preprocessor.transform(X_test)\n",
    "        \n",
    "        best_score = np.inf\n",
    "        best_params = {}\n",
    "        train_score=[]\n",
    "        val_score = []\n",
    "        \n",
    "        # Check if the ML algorithm is XGBoost\n",
    "        is_xgboost = isinstance(ml_algo, XGBRegressor)\n",
    "        \n",
    "        # Iterate over each combination of parameters\n",
    "        for params in ParameterGrid(param_grid):\n",
    "\n",
    "            model = ml_algo.set_params(**params)\n",
    "            if not is_xgboost:\n",
    "                model.fit(X_train, y_train)\n",
    "            else:\n",
    "                model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "            train_score.append(mean_squared_error(y_train, y_train_pred))\n",
    "            val_score.append(mean_squared_error(y_val, y_val_pred))\n",
    "            \n",
    "            # Update best parameters and score if current score is better\n",
    "            if val_score[-1] < best_score:\n",
    "                best_score = val_score[-1]\n",
    "                best_params = params\n",
    "                \n",
    "#         Plot the results\n",
    "#         param_name = list(param_grid.keys())[0]\n",
    "#         param_values = param_grid[param_name]\n",
    "        \n",
    "#         plt.figure(figsize=(6,4))\n",
    "#         plt.semilogx(param_values, train_score, label='Train Score', marker='o')\n",
    "#         plt.semilogx(param_values, val_score, label='Validation Score', marker='o')\n",
    "#         plt.xlabel('Parameter')\n",
    "#         plt.ylabel('Mean Squared Error')\n",
    "#         plt.legend()\n",
    "#         plt.title('Grid Search Results')\n",
    "#         plt.show()\n",
    "        \n",
    "        best_models.append(ml_algo.set_params(**best_params))\n",
    "    \n",
    "        # calculate and save the test score\n",
    "        y_test_pred = best_models[-1].predict(X_test)\n",
    "        vw_ret = value_weighted_ret(X.loc[test_idx,'mvel1'],y_test)\n",
    "        vw_ret_pred = value_weighted_ret(X.loc[test_idx,'mvel1'],y_test_pred)\n",
    "        test_scores.append(mean_squared_error(vw_ret,vw_ret_pred))\n",
    "  \n",
    "    return test_scores, best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48412af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[new_char+['sic2']].fillna(0)\n",
    "y = df['ret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c93c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate baseline score\n",
    "baseline_score = []\n",
    "for train_idx, val_idx, test_idx in recursive_split(df_date):\n",
    "    # Split the data\n",
    "    X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n",
    "    X_test, y_test = X.loc[test_idx], y.loc[test_idx]\n",
    "    baseline_pred = np.zeros(len(X_test))\n",
    "    baseline_score.append(mean_squared_error(y_test,baseline_pred))\n",
    "print(f\"mean of test scores: {np.mean(baseline_score)} \\n\\\n",
    "standard deviation of test scores: {np.std(baseline_score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e19ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "start_time = time.time()\n",
    "pcr_ = make_pipeline(PCA(), LinearRegression())\n",
    "param_grid = {\n",
    "    'pca__n_components': [1,3,5,7]\n",
    "}\n",
    "pcr_test_scores, pcr_best_models = ML_pipeline(X, y, preprocessor, pcr_, param_grid)\n",
    "\n",
    "# Save the model to disk\n",
    "filename = 'results/pcr_model.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(pcr_best_models, file)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Execution time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a7ef1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# linear regression model (l1 regularization)\n",
    "start_time = time.time()\n",
    "lasso_ = Lasso(max_iter=100000000)\n",
    "param_grid = {'alpha': np.logspace(-4,-1,10)}\n",
    "lasso_test_scores, lasso_best_models = ML_pipeline(X, y, preprocessor, lasso_, param_grid)\n",
    "filename = 'results/lasso_model.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(lasso_best_models, file)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Execution time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0480aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest regression\n",
    "start_time = time.time()\n",
    "rfr_ = RandomForestRegressor(random_state = 42,n_jobs=-1)\n",
    "param_grid = {\n",
    "    'n_estimators': [200],\n",
    "    'max_depth': [1, 2, 3, 6],\n",
    "    'max_features': [3, 5, 10, 20],\n",
    "    'random_state': [1, 42, 58, 69, 72]\n",
    "}\n",
    "rfr_test_scores, rfr_best_models, rfr_vw_ret, rfr_vw_ret_pred= ML_pipeline(X, y, preprocessor, rfr_, param_grid)\n",
    "\n",
    "filename = 'results/rf_model.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(rf_best_models, file)\n",
    "    \n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Execution time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f0a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost regression\n",
    "start_time = time.time()\n",
    "xgb_ = xgboost.XGBRegressor()\n",
    "param_grid = {\"learning_rate\": [0.03, 0.1],\n",
    "              \"n_estimators\": [10000],\n",
    "              \"max_depth\": [1, 2, 3, 6, 10],\n",
    "              \"early_stopping_rounds\": [50]}\n",
    "\n",
    "xgb_test_scores, xgb_best_models, xgb_vw_ret, xgb_vw_ret_pred= ML_pipeline(X, y, preprocessor, xgb_, param_grid)\n",
    "\n",
    "filename = 'results/xgb_model.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(xgb_best_models, file)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Execution time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f953e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model Comparison\n",
    "import math\n",
    "models = ['PCR', 'Lasso', 'Random Forest', 'XGBoost']\n",
    "scores = [pcr_mse,lasso_mse,rfr_mse,xgb_mse]\n",
    "rmse_means = [np.mean([math.sqrt(sc) for sc in score]) for score in scores]  \n",
    "rmse_stds = [np.std([math.sqrt(sc) for sc in score]) for score in scores]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(6,4))  # Set the figure size\n",
    "plt.bar(models, rmse_means, yerr=rmse_stds, capsize=10) \n",
    "plt.axhline(y=np.mean(np.sqrt(base_mse)), color='r', linestyle='-', label=f'Baseline RMSE = {np.mean(np.sqrt(base_mse)):.4f}')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE for Different ML Algorithms') \n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/comparison.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b062de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting true values vs predicted values\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(y.index, y, label='True Values')\n",
    "plt.plot(y.index, best_model.predict(X), label='Predicted Values')\n",
    "\n",
    "plt.title('True vs Predicted SP500 return')\n",
    "plt.legend()\n",
    "plt.savefig('figures/predictions.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4aaf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate permutation importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "import shap\n",
    "\n",
    "perm_importance = permutation_importance(best_model, X_test, y_test, n_repeats=10, random_state=0, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "# Calculate SHAP values\n",
    "explainer = shap.Explainer(best_model, X_train)\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddd5364",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = perm_importance.importances_mean.argsort()[-10:]\n",
    "feature_names = X.columns\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(perm_importance.importances[sorted_idx].T,\n",
    "           vert=False, labels=feature_names[sorted_idx])\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "ax.set_xlabel('Neg_RMSE reduction with perturbed feature')\n",
    "fig.tight_layout()\n",
    "plt.savefig('figures/perm_importance.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb1aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_total_gain = best_model.get_booster().get_score(importance_type='total_gain')\n",
    "sorted_importance_total_gain = sorted(importance_total_gain.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "def plot_feature_importances(importances, title, ax):\n",
    "    sorted_features, sorted_scores = zip(*importances)\n",
    "    ax.barh(sorted_features, sorted_scores)\n",
    "    ax.set_xlabel('Feature Importance')\n",
    "    ax.set_title(title)\n",
    "    ax.invert_yaxis()  # Invert y-axis to show the most important feature at the top\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(5, 4))\n",
    "plot_feature_importances(sorted_importance_total_gain, 'Features Importance by Total Gain', axes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/total_gain.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_sum = np.abs(shap_values.values).mean(axis=0)\n",
    "\n",
    "feature_importance = pd.DataFrame([feature_names, shap_sum]).T\n",
    "feature_importance.columns = ['Feature', 'SHAP Importance']\n",
    "\n",
    "sorted_feature_importance = feature_importance.sort_values(by='SHAP Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.barh(sorted_feature_importance['Feature'][:10], sorted_feature_importance['SHAP Importance'][:10])\n",
    "plt.xlabel('SHAP Importance')\n",
    "plt.title('Feature Importance by SHAP')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig('figures/global_shap.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c673a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "for i in [10, 30]:\n",
    "    shap_values_point = shap_values.values[i]\n",
    "    expected_value = shap_values.base_values[i]\n",
    "    plt.figure()\n",
    "    shap.force_plot(explainer.expected_value, shap_values_point, feature_names = feature_names, matplotlib=True) \n",
    "    plt.savefig(f'figures/local_shap_{i}.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
